{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rsryc2Piskoo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bowling_df = pd.read_csv(\"/content/bowl.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['O', 'M', 'R', 'W', 'ECON', '0s', '4s', '6s', 'WD', 'NB', 'ID',\n",
              "       'Opposite'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bowling_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9000000\n",
            "36/36 [==============================] - 1s 11ms/step - loss: 0.4559 - mean_absolute_error: 0.3922 - val_loss: 0.3259 - val_mean_absolute_error: 0.4159\n",
            "Epoch 2/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3836 - mean_absolute_error: 0.4409 - val_loss: 0.3134 - val_mean_absolute_error: 0.4279\n",
            "Epoch 3/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3697 - mean_absolute_error: 0.4314 - val_loss: 0.3069 - val_mean_absolute_error: 0.4220\n",
            "Epoch 4/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3665 - mean_absolute_error: 0.4277 - val_loss: 0.3018 - val_mean_absolute_error: 0.4133\n",
            "Epoch 5/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3591 - mean_absolute_error: 0.4214 - val_loss: 0.2997 - val_mean_absolute_error: 0.4093\n",
            "Epoch 6/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3639 - mean_absolute_error: 0.4146 - val_loss: 0.2979 - val_mean_absolute_error: 0.4120\n",
            "Epoch 7/9000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.3654 - mean_absolute_error: 0.4239 - val_loss: 0.2962 - val_mean_absolute_error: 0.4106\n",
            "Epoch 8/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3546 - mean_absolute_error: 0.4141 - val_loss: 0.2955 - val_mean_absolute_error: 0.4112\n",
            "Epoch 9/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3577 - mean_absolute_error: 0.4199 - val_loss: 0.2948 - val_mean_absolute_error: 0.4055\n",
            "Epoch 10/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3554 - mean_absolute_error: 0.4141 - val_loss: 0.2948 - val_mean_absolute_error: 0.4128\n",
            "Epoch 11/9000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.3509 - mean_absolute_error: 0.4206 - val_loss: 0.2941 - val_mean_absolute_error: 0.4108\n",
            "Epoch 12/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3549 - mean_absolute_error: 0.4193 - val_loss: 0.2933 - val_mean_absolute_error: 0.4111\n",
            "Epoch 13/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3562 - mean_absolute_error: 0.4184 - val_loss: 0.2928 - val_mean_absolute_error: 0.4083\n",
            "Epoch 14/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3557 - mean_absolute_error: 0.4147 - val_loss: 0.2929 - val_mean_absolute_error: 0.4118\n",
            "Epoch 15/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3522 - mean_absolute_error: 0.4146 - val_loss: 0.2927 - val_mean_absolute_error: 0.4085\n",
            "Epoch 16/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3509 - mean_absolute_error: 0.4115 - val_loss: 0.2925 - val_mean_absolute_error: 0.4087\n",
            "Epoch 17/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3483 - mean_absolute_error: 0.4131 - val_loss: 0.2925 - val_mean_absolute_error: 0.4123\n",
            "Epoch 18/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3498 - mean_absolute_error: 0.4144 - val_loss: 0.2912 - val_mean_absolute_error: 0.4072\n",
            "Epoch 19/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3531 - mean_absolute_error: 0.4143 - val_loss: 0.2915 - val_mean_absolute_error: 0.4114\n",
            "Epoch 20/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3499 - mean_absolute_error: 0.4143 - val_loss: 0.2920 - val_mean_absolute_error: 0.4092\n",
            "Epoch 21/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3511 - mean_absolute_error: 0.4165 - val_loss: 0.2921 - val_mean_absolute_error: 0.4099\n",
            "Epoch 22/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3532 - mean_absolute_error: 0.4111 - val_loss: 0.2917 - val_mean_absolute_error: 0.4066\n",
            "Epoch 23/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3506 - mean_absolute_error: 0.4079 - val_loss: 0.2924 - val_mean_absolute_error: 0.4110\n",
            "Epoch 24/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3573 - mean_absolute_error: 0.4201 - val_loss: 0.2922 - val_mean_absolute_error: 0.4117\n",
            "Epoch 25/9000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.3485 - mean_absolute_error: 0.4145 - val_loss: 0.2930 - val_mean_absolute_error: 0.4160\n",
            "Epoch 26/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3524 - mean_absolute_error: 0.4183 - val_loss: 0.2925 - val_mean_absolute_error: 0.4105\n",
            "Epoch 27/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3419 - mean_absolute_error: 0.4097 - val_loss: 0.2927 - val_mean_absolute_error: 0.4128\n",
            "Epoch 28/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3476 - mean_absolute_error: 0.4124 - val_loss: 0.2914 - val_mean_absolute_error: 0.4089\n",
            "Epoch 29/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3490 - mean_absolute_error: 0.4098 - val_loss: 0.2914 - val_mean_absolute_error: 0.4126\n",
            "Epoch 30/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3482 - mean_absolute_error: 0.4106 - val_loss: 0.2918 - val_mean_absolute_error: 0.4127\n",
            "Epoch 31/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3482 - mean_absolute_error: 0.4103 - val_loss: 0.2923 - val_mean_absolute_error: 0.4138\n",
            "Epoch 32/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3471 - mean_absolute_error: 0.4108 - val_loss: 0.2922 - val_mean_absolute_error: 0.4084\n",
            "Epoch 33/9000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.3526 - mean_absolute_error: 0.4084 - val_loss: 0.2923 - val_mean_absolute_error: 0.4092\n",
            "Epoch 34/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3524 - mean_absolute_error: 0.4124 - val_loss: 0.2927 - val_mean_absolute_error: 0.4129\n",
            "Epoch 35/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3471 - mean_absolute_error: 0.4103 - val_loss: 0.2931 - val_mean_absolute_error: 0.4166\n",
            "Epoch 36/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3509 - mean_absolute_error: 0.4156 - val_loss: 0.2933 - val_mean_absolute_error: 0.4105\n",
            "Epoch 37/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3450 - mean_absolute_error: 0.4073 - val_loss: 0.2928 - val_mean_absolute_error: 0.4133\n",
            "Epoch 38/9000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.3445 - mean_absolute_error: 0.4057 - val_loss: 0.2933 - val_mean_absolute_error: 0.4174\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2592 - mean_absolute_error: 0.3813\n",
            "Test Accuracy: 0.3812803030014038\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "# X and y should be numpy arrays or pandas DataFrames\n",
        "X = bowling_df[['ID', 'Opposite','O','W']]\n",
        "y = bowling_df[['M']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))  # Adjust dropout rate\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Adjust dropout rate\n",
        "\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Adjust dropout rate\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='linear'))  # Use 'linear' for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error',  optimizer = SGD(learning_rate=0.001, momentum=0.9), metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=9000000, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6000000\n",
            "36/36 [==============================] - 1s 8ms/step - loss: 2.0117 - mean_absolute_error: 1.0861 - val_loss: 1.6285 - val_mean_absolute_error: 1.0131\n",
            "Epoch 2/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5583 - mean_absolute_error: 0.9962 - val_loss: 1.5197 - val_mean_absolute_error: 0.9502\n",
            "Epoch 3/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3920 - mean_absolute_error: 0.9332 - val_loss: 1.4201 - val_mean_absolute_error: 0.9247\n",
            "Epoch 4/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.4533 - mean_absolute_error: 0.9527 - val_loss: 1.4245 - val_mean_absolute_error: 0.9127\n",
            "Epoch 5/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3991 - mean_absolute_error: 0.9297 - val_loss: 1.3789 - val_mean_absolute_error: 0.9081\n",
            "Epoch 6/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3787 - mean_absolute_error: 0.9183 - val_loss: 1.3776 - val_mean_absolute_error: 0.9048\n",
            "Epoch 7/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3537 - mean_absolute_error: 0.9136 - val_loss: 1.4059 - val_mean_absolute_error: 0.9053\n",
            "Epoch 8/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3681 - mean_absolute_error: 0.9148 - val_loss: 1.3916 - val_mean_absolute_error: 0.9013\n",
            "Epoch 9/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3807 - mean_absolute_error: 0.9183 - val_loss: 1.3869 - val_mean_absolute_error: 0.9016\n",
            "Epoch 10/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3693 - mean_absolute_error: 0.9150 - val_loss: 1.3848 - val_mean_absolute_error: 0.9039\n",
            "Epoch 11/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3844 - mean_absolute_error: 0.9279 - val_loss: 1.3952 - val_mean_absolute_error: 0.9061\n",
            "Epoch 12/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3483 - mean_absolute_error: 0.9047 - val_loss: 1.3794 - val_mean_absolute_error: 0.9024\n",
            "Epoch 13/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3043 - mean_absolute_error: 0.8869 - val_loss: 1.3494 - val_mean_absolute_error: 0.8960\n",
            "Epoch 14/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3166 - mean_absolute_error: 0.9028 - val_loss: 1.3546 - val_mean_absolute_error: 0.8926\n",
            "Epoch 15/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3452 - mean_absolute_error: 0.9013 - val_loss: 1.3713 - val_mean_absolute_error: 0.8974\n",
            "Epoch 16/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3135 - mean_absolute_error: 0.8966 - val_loss: 1.3613 - val_mean_absolute_error: 0.8980\n",
            "Epoch 17/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3040 - mean_absolute_error: 0.8937 - val_loss: 1.3569 - val_mean_absolute_error: 0.8962\n",
            "Epoch 18/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3384 - mean_absolute_error: 0.9026 - val_loss: 1.3657 - val_mean_absolute_error: 0.8980\n",
            "Epoch 19/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3254 - mean_absolute_error: 0.9019 - val_loss: 1.3654 - val_mean_absolute_error: 0.8986\n",
            "Epoch 20/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3390 - mean_absolute_error: 0.9062 - val_loss: 1.3688 - val_mean_absolute_error: 0.8977\n",
            "Epoch 21/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3021 - mean_absolute_error: 0.8870 - val_loss: 1.3513 - val_mean_absolute_error: 0.8966\n",
            "Epoch 22/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3165 - mean_absolute_error: 0.9009 - val_loss: 1.3634 - val_mean_absolute_error: 0.8977\n",
            "Epoch 23/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3307 - mean_absolute_error: 0.9023 - val_loss: 1.3543 - val_mean_absolute_error: 0.8985\n",
            "Epoch 24/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3222 - mean_absolute_error: 0.8997 - val_loss: 1.3493 - val_mean_absolute_error: 0.9011\n",
            "Epoch 25/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3077 - mean_absolute_error: 0.8976 - val_loss: 1.3705 - val_mean_absolute_error: 0.9007\n",
            "Epoch 26/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3242 - mean_absolute_error: 0.8954 - val_loss: 1.3642 - val_mean_absolute_error: 0.9038\n",
            "Epoch 27/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3037 - mean_absolute_error: 0.8936 - val_loss: 1.3642 - val_mean_absolute_error: 0.9005\n",
            "Epoch 28/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3277 - mean_absolute_error: 0.8989 - val_loss: 1.3705 - val_mean_absolute_error: 0.9058\n",
            "Epoch 29/6000000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.3123 - mean_absolute_error: 0.8992 - val_loss: 1.3744 - val_mean_absolute_error: 0.9036\n",
            "Epoch 30/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3112 - mean_absolute_error: 0.8986 - val_loss: 1.3781 - val_mean_absolute_error: 0.9007\n",
            "Epoch 31/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.2941 - mean_absolute_error: 0.8965 - val_loss: 1.3629 - val_mean_absolute_error: 0.9047\n",
            "Epoch 32/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.3032 - mean_absolute_error: 0.8876 - val_loss: 1.3893 - val_mean_absolute_error: 0.9024\n",
            "Epoch 33/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.3193 - mean_absolute_error: 0.8880 - val_loss: 1.3718 - val_mean_absolute_error: 0.9035\n",
            "Epoch 34/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.3037 - mean_absolute_error: 0.8909 - val_loss: 1.3671 - val_mean_absolute_error: 0.9023\n",
            "Epoch 35/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2915 - mean_absolute_error: 0.8878 - val_loss: 1.3693 - val_mean_absolute_error: 0.9025\n",
            "Epoch 36/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2969 - mean_absolute_error: 0.8883 - val_loss: 1.3681 - val_mean_absolute_error: 0.9037\n",
            "Epoch 37/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.3002 - mean_absolute_error: 0.8946 - val_loss: 1.3583 - val_mean_absolute_error: 0.9051\n",
            "Epoch 38/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.3056 - mean_absolute_error: 0.8934 - val_loss: 1.3559 - val_mean_absolute_error: 0.9025\n",
            "Epoch 39/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2970 - mean_absolute_error: 0.8935 - val_loss: 1.3616 - val_mean_absolute_error: 0.9033\n",
            "Epoch 40/6000000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 1.2914 - mean_absolute_error: 0.8896 - val_loss: 1.3533 - val_mean_absolute_error: 0.9001\n",
            "Epoch 41/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2886 - mean_absolute_error: 0.8904 - val_loss: 1.3493 - val_mean_absolute_error: 0.8997\n",
            "Epoch 42/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2706 - mean_absolute_error: 0.8809 - val_loss: 1.3589 - val_mean_absolute_error: 0.8983\n",
            "Epoch 43/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.3202 - mean_absolute_error: 0.8972 - val_loss: 1.3672 - val_mean_absolute_error: 0.9020\n",
            "Epoch 44/6000000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 1.2922 - mean_absolute_error: 0.8913 - val_loss: 1.3654 - val_mean_absolute_error: 0.9001\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0503 - mean_absolute_error: 0.8498\n",
            "Test Accuracy: 0.8498480319976807\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "# X and y should be numpy arrays or pandas DataFrames\n",
        "X = bowling_df[['ID', 'Opposite','O']]\n",
        "y = bowling_df[['W']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='linear'))  # Use 'linear' for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error',  optimizer = SGD(learning_rate=0.001, momentum=0.9), metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=6000000, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('your_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model('your_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['your_model.pkl']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained TensorFlow model\n",
        "# ...\n",
        "\n",
        "# Save the model to a pickle file\n",
        "joblib.dump(model, 'your_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = joblib.load('your_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6ydAzG7svWV"
      },
      "outputs": [],
      "source": [
        "batting_df = pd.read_csv(\"/content/bat.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vihYWTxRs1_W",
        "outputId": "062759aa-7b10-4081-ec55-508944041061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqFhrMEWyaS_",
        "outputId": "abe266bd-2ea1-4ca5-8da2-6fbd53b9fb43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5000000\n",
            "56/56 [==============================] - 2s 8ms/step - loss: 967.2916 - mean_absolute_error: 18.4159 - val_loss: 4609.7041 - val_mean_absolute_error: 53.2858\n",
            "Epoch 2/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 3/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 4/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 5/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 6/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 7/5000000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 8/5000000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 9/5000000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 10/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 11/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 12/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 13/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 14/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 15/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 16/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 17/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 18/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 19/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 20/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "Epoch 21/5000000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4762.0190 - mean_absolute_error: 54.2251\n",
            "Test Accuracy: 54.22509765625\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "# X and y should be numpy arrays or pandas DataFrames\n",
        "X = batting_df[['ID', 'M', 'B']]\n",
        "y = batting_df[['R']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='linear'))  # Use 'linear' for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error',  optimizer = SGD(learning_rate=0.001, momentum=0.9), metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=5000000, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng9CRUGsK3xs",
        "outputId": "d209df17-7610-4a82-c847-49f0ac66cfd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['R', 'B', 'M', '4s', '6s', 'SR', 'ID', 'Opposite'], dtype='object')"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batting_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK6AuCxHK7WR",
        "outputId": "c8a4a7df-e0c9-4452-d588-e8c4f24e35d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50000\n",
            "56/56 [==============================] - 1s 9ms/step - loss: 5.9887 - mean_absolute_error: 1.6654 - val_loss: 2.2962 - val_mean_absolute_error: 1.1367\n",
            "Epoch 2/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 3.9821 - mean_absolute_error: 1.3637 - val_loss: 2.2501 - val_mean_absolute_error: 1.1053\n",
            "Epoch 3/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 3.0401 - mean_absolute_error: 1.2136 - val_loss: 1.7491 - val_mean_absolute_error: 0.9641\n",
            "Epoch 4/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 3.2401 - mean_absolute_error: 1.1910 - val_loss: 1.6317 - val_mean_absolute_error: 0.9372\n",
            "Epoch 5/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 3.0600 - mean_absolute_error: 1.1630 - val_loss: 1.5182 - val_mean_absolute_error: 0.8866\n",
            "Epoch 6/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 2.8179 - mean_absolute_error: 1.1399 - val_loss: 1.4842 - val_mean_absolute_error: 0.8838\n",
            "Epoch 7/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8988 - mean_absolute_error: 1.1289 - val_loss: 1.4917 - val_mean_absolute_error: 0.8845\n",
            "Epoch 8/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.6521 - mean_absolute_error: 1.1006 - val_loss: 1.4116 - val_mean_absolute_error: 0.8472\n",
            "Epoch 9/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.5304 - mean_absolute_error: 1.0729 - val_loss: 1.4000 - val_mean_absolute_error: 0.8672\n",
            "Epoch 10/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4068 - mean_absolute_error: 1.0439 - val_loss: 1.8744 - val_mean_absolute_error: 0.9765\n",
            "Epoch 11/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5594 - mean_absolute_error: 1.0659 - val_loss: 1.3470 - val_mean_absolute_error: 0.8321\n",
            "Epoch 12/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2717 - mean_absolute_error: 1.0323 - val_loss: 1.3706 - val_mean_absolute_error: 0.8348\n",
            "Epoch 13/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.4200 - mean_absolute_error: 1.0364 - val_loss: 1.4788 - val_mean_absolute_error: 0.8702\n",
            "Epoch 14/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.5999 - mean_absolute_error: 1.0601 - val_loss: 1.7641 - val_mean_absolute_error: 0.9341\n",
            "Epoch 15/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.5180 - mean_absolute_error: 1.0530 - val_loss: 1.8696 - val_mean_absolute_error: 0.9627\n",
            "Epoch 16/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.4560 - mean_absolute_error: 1.0613 - val_loss: 1.3916 - val_mean_absolute_error: 0.8485\n",
            "Epoch 17/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2029 - mean_absolute_error: 1.0050 - val_loss: 1.3465 - val_mean_absolute_error: 0.8371\n",
            "Epoch 18/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3529 - mean_absolute_error: 1.0357 - val_loss: 1.6199 - val_mean_absolute_error: 0.9051\n",
            "Epoch 19/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4494 - mean_absolute_error: 1.0175 - val_loss: 1.3568 - val_mean_absolute_error: 0.8484\n",
            "Epoch 20/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.6386 - mean_absolute_error: 1.0818 - val_loss: 1.3679 - val_mean_absolute_error: 0.8359\n",
            "Epoch 21/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3771 - mean_absolute_error: 1.0431 - val_loss: 1.4339 - val_mean_absolute_error: 0.8666\n",
            "Epoch 22/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5765 - mean_absolute_error: 1.0471 - val_loss: 1.3772 - val_mean_absolute_error: 0.8188\n",
            "Epoch 23/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3009 - mean_absolute_error: 1.0314 - val_loss: 1.4638 - val_mean_absolute_error: 0.8762\n",
            "Epoch 24/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2150 - mean_absolute_error: 0.9911 - val_loss: 1.4401 - val_mean_absolute_error: 0.8701\n",
            "Epoch 25/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3024 - mean_absolute_error: 1.0082 - val_loss: 1.3587 - val_mean_absolute_error: 0.8287\n",
            "Epoch 26/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4043 - mean_absolute_error: 1.0475 - val_loss: 1.3450 - val_mean_absolute_error: 0.8225\n",
            "Epoch 27/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3006 - mean_absolute_error: 1.0210 - val_loss: 1.3735 - val_mean_absolute_error: 0.8467\n",
            "Epoch 28/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1513 - mean_absolute_error: 1.0231 - val_loss: 1.4063 - val_mean_absolute_error: 0.8517\n",
            "Epoch 29/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.2533 - mean_absolute_error: 0.9982 - val_loss: 1.3719 - val_mean_absolute_error: 0.8401\n",
            "Epoch 30/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3306 - mean_absolute_error: 1.0104 - val_loss: 1.4013 - val_mean_absolute_error: 0.8364\n",
            "Epoch 31/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3527 - mean_absolute_error: 1.0258 - val_loss: 1.4030 - val_mean_absolute_error: 0.8348\n",
            "Epoch 32/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2366 - mean_absolute_error: 1.0032 - val_loss: 1.4258 - val_mean_absolute_error: 0.8589\n",
            "Epoch 33/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.1786 - mean_absolute_error: 1.0070 - val_loss: 1.3538 - val_mean_absolute_error: 0.8296\n",
            "Epoch 34/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.9554 - mean_absolute_error: 0.9753 - val_loss: 1.3607 - val_mean_absolute_error: 0.8379\n",
            "Epoch 35/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.1957 - mean_absolute_error: 1.0149 - val_loss: 1.3741 - val_mean_absolute_error: 0.8359\n",
            "Epoch 36/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.4624 - mean_absolute_error: 1.0347 - val_loss: 1.6347 - val_mean_absolute_error: 0.8988\n",
            "Epoch 37/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3358 - mean_absolute_error: 1.0174 - val_loss: 1.4088 - val_mean_absolute_error: 0.8510\n",
            "Epoch 38/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9951 - mean_absolute_error: 0.9651 - val_loss: 1.4689 - val_mean_absolute_error: 0.8401\n",
            "Epoch 39/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2695 - mean_absolute_error: 1.0017 - val_loss: 1.3831 - val_mean_absolute_error: 0.8426\n",
            "Epoch 40/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2621 - mean_absolute_error: 1.0189 - val_loss: 1.3852 - val_mean_absolute_error: 0.8499\n",
            "Epoch 41/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0933 - mean_absolute_error: 0.9752 - val_loss: 1.4155 - val_mean_absolute_error: 0.8484\n",
            "Epoch 42/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2469 - mean_absolute_error: 1.0090 - val_loss: 1.3920 - val_mean_absolute_error: 0.8301\n",
            "Epoch 43/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1828 - mean_absolute_error: 1.0064 - val_loss: 1.4279 - val_mean_absolute_error: 0.8580\n",
            "Epoch 44/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2625 - mean_absolute_error: 1.0205 - val_loss: 1.4591 - val_mean_absolute_error: 0.8313\n",
            "Epoch 45/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3094 - mean_absolute_error: 1.0085 - val_loss: 1.4176 - val_mean_absolute_error: 0.8526\n",
            "Epoch 46/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1204 - mean_absolute_error: 0.9972 - val_loss: 1.3931 - val_mean_absolute_error: 0.8464\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4553 - mean_absolute_error: 0.8545\n",
            "Test Accuracy: 0.8544950485229492\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "# X and y should be numpy arrays or pandas DataFrames\n",
        "X = batting_df[['R', 'B', 'M', 'ID', 'Opposite']]\n",
        "y = batting_df[['4s']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model_4 = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model_4.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model_4.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add hidden layers\n",
        "model_4.add(Dense(units=64, activation='relu'))\n",
        "model_4.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "model_4.add(Dense(units=32, activation='relu'))\n",
        "model_4.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add output layer\n",
        "model_4.add(Dense(units=1, activation='linear'))  # Use 'linear' for regression\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss='mean_squared_error',  optimizer = SGD(learning_rate=0.001, momentum=0.9), metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model_4.fit(X_train, y_train, epochs=50000, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model_4.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I3Iq3wKL6i7",
        "outputId": "51303606-1690-42a2-df26-9e2c14ebffad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50000\n",
            "56/56 [==============================] - 3s 8ms/step - loss: 39.5956 - mean_absolute_error: 1.0456 - val_loss: 1.1101 - val_mean_absolute_error: 0.8744\n",
            "Epoch 2/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 39.5184 - mean_absolute_error: 1.1304 - val_loss: 0.5789 - val_mean_absolute_error: 0.5352\n",
            "Epoch 3/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 38.4762 - mean_absolute_error: 0.9956 - val_loss: 1.1622 - val_mean_absolute_error: 0.7534\n",
            "Epoch 4/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 39.0539 - mean_absolute_error: 1.0986 - val_loss: 0.8087 - val_mean_absolute_error: 0.6933\n",
            "Epoch 5/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 39.5466 - mean_absolute_error: 1.1208 - val_loss: 0.6995 - val_mean_absolute_error: 0.6609\n",
            "Epoch 6/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 39.3178 - mean_absolute_error: 0.9864 - val_loss: 0.6401 - val_mean_absolute_error: 0.6452\n",
            "Epoch 7/50000\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 38.2917 - mean_absolute_error: 1.0561 - val_loss: 0.5248 - val_mean_absolute_error: 0.5262\n",
            "Epoch 8/50000\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 36.0667 - mean_absolute_error: 1.3067 - val_loss: 0.9072 - val_mean_absolute_error: 0.7748\n",
            "Epoch 9/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.8206 - mean_absolute_error: 1.1009 - val_loss: 0.8044 - val_mean_absolute_error: 0.7044\n",
            "Epoch 10/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.6559 - mean_absolute_error: 1.0629 - val_loss: 0.7551 - val_mean_absolute_error: 0.6785\n",
            "Epoch 11/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 38.9957 - mean_absolute_error: 1.0310 - val_loss: 0.7275 - val_mean_absolute_error: 0.7248\n",
            "Epoch 12/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 38.6837 - mean_absolute_error: 1.0964 - val_loss: 0.6738 - val_mean_absolute_error: 0.5126\n",
            "Epoch 13/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 35.8356 - mean_absolute_error: 1.0347 - val_loss: 0.7998 - val_mean_absolute_error: 0.6861\n",
            "Epoch 14/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 37.7259 - mean_absolute_error: 1.2007 - val_loss: 0.9173 - val_mean_absolute_error: 0.7034\n",
            "Epoch 15/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 40.0714 - mean_absolute_error: 1.2045 - val_loss: 1.0673 - val_mean_absolute_error: 0.8522\n",
            "Epoch 16/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 40.0071 - mean_absolute_error: 1.1360 - val_loss: 1.0000 - val_mean_absolute_error: 0.8340\n",
            "Epoch 17/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.7158 - mean_absolute_error: 1.1498 - val_loss: 0.8027 - val_mean_absolute_error: 0.6921\n",
            "Epoch 18/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.6913 - mean_absolute_error: 1.0785 - val_loss: 0.8016 - val_mean_absolute_error: 0.7172\n",
            "Epoch 19/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.8002 - mean_absolute_error: 1.1411 - val_loss: 0.9377 - val_mean_absolute_error: 0.8278\n",
            "Epoch 20/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.5738 - mean_absolute_error: 1.1075 - val_loss: 0.8790 - val_mean_absolute_error: 0.7852\n",
            "Epoch 21/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.5926 - mean_absolute_error: 1.1257 - val_loss: 0.8258 - val_mean_absolute_error: 0.7588\n",
            "Epoch 22/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.6128 - mean_absolute_error: 1.1069 - val_loss: 0.8426 - val_mean_absolute_error: 0.7791\n",
            "Epoch 23/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.1960 - mean_absolute_error: 1.1409 - val_loss: 0.8345 - val_mean_absolute_error: 0.6923\n",
            "Epoch 24/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 39.5558 - mean_absolute_error: 1.1249 - val_loss: 0.8521 - val_mean_absolute_error: 0.7143\n",
            "Epoch 25/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 38.2195 - mean_absolute_error: 1.1422 - val_loss: 0.7183 - val_mean_absolute_error: 0.6367\n",
            "Epoch 26/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 38.9272 - mean_absolute_error: 0.9957 - val_loss: 0.8354 - val_mean_absolute_error: 0.7440\n",
            "Epoch 27/50000\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 33.1354 - mean_absolute_error: 1.2242 - val_loss: 0.8895 - val_mean_absolute_error: 0.7250\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 21.8980 - mean_absolute_error: 0.9034\n",
            "Test Accuracy: 0.903441846370697\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix and y is your target variable\n",
        "# X and y should be numpy arrays or pandas DataFrames\n",
        "X = batting_df[['R', 'B', 'M', 'ID', 'Opposite']]\n",
        "y = batting_df[['6s']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model_6s = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model_6s.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model_6s.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add hidden layers\n",
        "model_6s.add(Dense(units=64, activation='relu'))\n",
        "model_6s.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "model_6s.add(Dense(units=32, activation='relu'))\n",
        "model_6s.add(Dropout(0.3))  # Adjust dropout rate\n",
        "\n",
        "# Add output layer\n",
        "model_6s.add(Dense(units=1, activation='linear'))  # Use 'linear' for regression\n",
        "\n",
        "# Compile the model\n",
        "model_6s.compile(loss='mean_squared_error',  optimizer = SGD(learning_rate=0.001, momentum=0.9), metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model_6s.fit(X_train, y_train, epochs=50000, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model_6s.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTWa178JX5CL"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_4.save('your_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FDHYYwTX9Ir"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model('your_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7C5l-g6Yms8",
        "outputId": "ae1c4f1a-4e6b-41a6-b0d6-3fa705889356"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['your_model.pkl']"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained TensorFlow model\n",
        "# ...\n",
        "\n",
        "# Save the model to a pickle file\n",
        "joblib.dump(model_4, 'your_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIVmUFVEYqBJ"
      },
      "outputs": [],
      "source": [
        "# Load the model from the pickle file\n",
        "loaded_model = joblib.load('your_model.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
